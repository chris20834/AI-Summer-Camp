{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhPMGETvVsQ0QlFhSSGQ4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chris20834/AI-Summer-Camp/blob/main/GAN_Inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. 安裝必要套件"
      ],
      "metadata": {
        "id": "myHUxTqAvP8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_uHdhptvF7G"
      },
      "outputs": [],
      "source": [
        "#!pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. 數據集下載與遮罩函數"
      ],
      "metadata": {
        "id": "hvE0uLKywvWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # 匯入 PyTorch 主套件，用於 tensor 運算與神經網路\n",
        "from torchvision import datasets, transforms  # 匯入 torchvision 的資料集與資料預處理模組\n",
        "from torch.utils.data import DataLoader  # 匯入 DataLoader，用於批次資料載入\n",
        "import matplotlib.pyplot as plt  # 匯入 matplotlib，用於畫圖顯示\n",
        "\n",
        "# 定義一個資料轉換：將圖片轉為 Tensor 格式（0~1，且多增加一個 channel 維度）\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# 載入 MNIST 手寫數字訓練資料集\n",
        "# root: 資料存放路徑\n",
        "# train=True: 使用訓練集\n",
        "# download=True: 如果沒有資料就下載\n",
        "# transform=transform: 圖片先做 ToTensor 處理\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# 建立 DataLoader，設定 batch 大小為 64，並在每個 epoch 隨機打亂\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# 定義遮罩函式，將圖片中央的正方形區塊設為 0（黑色遮罩）\n",
        "def mask_center(imgs, size=14):\n",
        "    imgs = imgs.clone()  # 複製一份，不修改原 tensor\n",
        "    c = imgs.size(2) // 2  # 取得圖片中心點座標（以height為例：28//2=14）\n",
        "    l = size // 2  # 遮罩區塊半徑（例如size=14時，l=7）\n",
        "    # 遮罩中央區塊：[中心-l, 中心+l)，同時套用於高度和寬度\n",
        "    imgs[:, :, c-l:c+l, c-l:c+l] = 0\n",
        "    return imgs  # 回傳加上中央遮罩的新圖片張量"
      ],
      "metadata": {
        "id": "xn4MRUWXvKlS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. 建立 Generator & Discriminator"
      ],
      "metadata": {
        "id": "LXggN-Hvw0zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Generator：UNet 結構的簡單實作，包含 Encoder、Decoder 和 skip connection\n",
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Encoder: 兩層卷積，逐步下採樣\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1),  # 第一層卷積，輸入通道1，輸出64，kernel=4, stride=2, padding=1\n",
        "            nn.ReLU()                   # 啟用函數\n",
        "        )\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), # 第二層卷積，輸入64，輸出128\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Decoder: 兩層反卷積（上採樣）\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 第一層反卷積，從128回到64，output size 14x14\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 1, 4, 2, 1),   # 最後一層反卷積，輸入128(=64+64)，輸出1通道（灰階），output 28x28\n",
        "            nn.Tanh()  # 將輸出壓到 [-1, 1]，適合生成對抗網路的output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)           # 輸入x，經第一層encoder，shape: (batch, 64, 14, 14)\n",
        "        e2 = self.enc2(e1)          # 經第二層encoder，shape: (batch, 128, 7, 7)\n",
        "        d1 = self.dec1(e2)          # decoder第一層，up-sample到 (batch, 64, 14, 14)\n",
        "        d1_cat = torch.cat([e1, d1], dim=1)  # 與 encoder1 的特徵圖做 channel 維度串接 (skip connection)，shape: (batch, 128, 14, 14)\n",
        "        out = self.dec2(d1_cat)     # 經最後一層反卷積還原至 (batch, 1, 28, 28)\n",
        "        return out\n",
        "\n",
        "# Discriminator：簡單的卷積分類器\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1),      # 第一層卷積，下採樣，輸出 shape (batch, 64, 4, 4)\n",
        "            nn.LeakyReLU(0.2),              # LeakyReLU 啟用函數\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),    # 第二層卷積，下採樣，輸出 shape (batch, 128, 2, 2)\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),                   # 展平成一維\n",
        "            nn.Linear(128*2*2, 1),          # 全連接層，輸入維度512(=128*2*2)，輸出1（真或假）\n",
        "            nn.Sigmoid()                    # Sigmoid輸出為0~1間，代表\"真實\"的機率\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.main(x)  # 前向傳播，傳入圖片，回傳為真的機率"
      ],
      "metadata": {
        "id": "Gwaa9hR5wr1X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4. 訓練（僅2個epoch，快速測試）"
      ],
      "metadata": {
        "id": "l7c-9wwMw5EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 建立 UNetGenerator 和 Discriminator，分別丟到 GPU（如果有）或 CPU\n",
        "G, D = UNetGenerator().to(device), Discriminator().to(device)\n",
        "loss_fn = nn.BCELoss()   # 二元交叉熵，判別器用於區分真偽\n",
        "l1_loss = nn.L1Loss()    # L1 損失（像素差異），鼓勵生成貼近真實\n",
        "\n",
        "# 建立 Adam optimizer，分別給 G 與 D\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=2e-4)\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=2e-4)\n",
        "\n",
        "# 訓練 2 個 epoch\n",
        "for epoch in range(2):\n",
        "    for imgs, _ in train_loader:   # 取出每一個 batch（imgs shape: [batch, 1, 28, 28]）\n",
        "        imgs = imgs.to(device)     # 放到指定運算裝置\n",
        "        masked = mask_center(imgs, size=8)  # 把中央 8x8 遮起來，模擬修復任務\n",
        "\n",
        "        # 只拿中央 8x8 區塊作為修復目標（ground truth）\n",
        "        real = imgs[:, :, 10:18, 10:18]\n",
        "        # Generator 修補後的結果，同樣只拿中央 8x8 區塊\n",
        "        fake = G(masked)[:, :, 10:18, 10:18]\n",
        "\n",
        "        # === 訓練 Discriminator ===\n",
        "        real_labels = torch.ones(imgs.size(0), 1, device=device)   # 真圖標記為 1\n",
        "        fake_labels = torch.zeros(imgs.size(0), 1, device=device)  # 假圖標記為 0\n",
        "        out_real = D(real)                 # D 判斷真圖\n",
        "        out_fake = D(fake.detach())        # D 判斷假圖（detach 保證不傳遞梯度到 G）\n",
        "        loss_D = (loss_fn(out_real, real_labels) + loss_fn(out_fake, fake_labels)) / 2  # 判別器損失為真假平均\n",
        "        opt_D.zero_grad(); loss_D.backward(); opt_D.step()  # 反向傳播並更新 D\n",
        "\n",
        "        # === 訓練 Generator ===\n",
        "        out_fake = D(fake)  # 用最新 G 結果再判斷一次\n",
        "        # Generator 損失 = 欺騙 D 的 loss + L1（像素）損失（權重 10 可調整）\n",
        "        loss_G = loss_fn(out_fake, real_labels) + 10 * l1_loss(fake, real)\n",
        "        opt_G.zero_grad(); loss_G.backward(); opt_G.step()  # 反向傳播並更新 G\n",
        "\n",
        "    # 每個 epoch 輸出一次 loss\n",
        "    print(f\"Epoch {epoch+1}/2 | Loss_D: {loss_D.item():.4f} | Loss_G: {loss_G.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gte-JeE2wtlQ",
        "outputId": "47e9ce6b-b444-4630-86d6-f1207893c48c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 | Loss_D: 0.6487 | Loss_G: 3.0212\n",
            "Epoch 2/2 | Loss_D: 0.6288 | Loss_G: 2.5088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. 展示修復效果"
      ],
      "metadata": {
        "id": "jvcqiGa_yRaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 從訓練資料中隨機取出一個 batch，並只用第一張圖做測試\n",
        "imgs, _ = next(iter(train_loader))\n",
        "test_img = imgs[0:1].to(device)  # 取出第 0 張圖，shape: [1, 1, 28, 28]\n",
        "\n",
        "# 用和訓練相同的遮罩方式，遮蔽中央 8x8 區塊\n",
        "masked = mask_center(test_img, size=8)\n",
        "\n",
        "with torch.no_grad():  # 測試時不用計算梯度（節省運算資源）\n",
        "    output = G(masked).cpu()  # 將遮罩圖丟到 Generator，產生修復圖，並移到 CPU\n",
        "    repaired = masked.cpu().clone()  # 複製遮罩圖當基底\n",
        "    # 只用 Generator 的 output 取代中央 8x8 區塊，其餘維持原遮罩圖\n",
        "    repaired[:, :, 10:18, 10:18] = output[:, :, 10:18, 10:18]\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "# 顯示原圖\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(test_img.cpu()[0][0], cmap='gray')\n",
        "plt.title('Original')\n",
        "plt.axis('off')\n",
        "# 顯示遮罩圖（中央 8x8 已遮蔽）\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(masked.cpu()[0][0], cmap='gray')\n",
        "plt.title('Masked')\n",
        "plt.axis('off')\n",
        "# 顯示修復圖（中央區塊已用 Generator 修補）\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(repaired[0][0], cmap='gray')\n",
        "plt.title('Repaired')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "MoZaK1yOw7k1",
        "outputId": "50fb46b2-7ebd-452a-addf-562a655c9d56"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZ597DUS4CS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q5s4-2nn4yfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o--ttbIA5njX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}