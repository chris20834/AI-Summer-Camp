{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmhHz603QBnDvBLZ2Vkgzt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chris20834/AI-Summer-Camp/blob/main/GAN_Inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. 安裝必要套件"
      ],
      "metadata": {
        "id": "myHUxTqAvP8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_uHdhptvF7G"
      },
      "outputs": [],
      "source": [
        "#!pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. 數據集下載與遮罩函數"
      ],
      "metadata": {
        "id": "hvE0uLKywvWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # 匯入 PyTorch 主套件，用於 tensor 運算與神經網路\n",
        "from torchvision import datasets, transforms  # 匯入 torchvision 的資料集與資料預處理模組\n",
        "from torch.utils.data import DataLoader  # 匯入 DataLoader，用於批次資料載入\n",
        "import matplotlib.pyplot as plt  # 匯入 matplotlib，用於畫圖顯示\n",
        "\n",
        "# 定義一個資料轉換：將圖片轉為 Tensor 格式（0~1，且多增加一個 channel 維度）\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# 載入 MNIST 手寫數字訓練資料集\n",
        "# root: 資料存放路徑\n",
        "# train=True: 使用訓練集\n",
        "# download=True: 如果沒有資料就下載\n",
        "# transform=transform: 圖片先做 ToTensor 處理\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# 建立 DataLoader，設定 batch 大小為 64，並在每個 epoch 隨機打亂\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# 定義遮罩函式，將圖片中央的正方形區塊設為 0（黑色遮罩）\n",
        "def mask_center(imgs, size=14):\n",
        "    imgs = imgs.clone()  # 複製一份，不修改原 tensor\n",
        "    c = imgs.size(2) // 2  # 取得圖片中心點座標（以height為例：28//2=14）\n",
        "    l = size // 2  # 遮罩區塊半徑（例如size=14時，l=7）\n",
        "    # 遮罩中央區塊：[中心-l, 中心+l)，同時套用於高度和寬度\n",
        "    imgs[:, :, c-l:c+l, c-l:c+l] = 0\n",
        "    return imgs  # 回傳加上中央遮罩的新圖片張量"
      ],
      "metadata": {
        "id": "xn4MRUWXvKlS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. 建立 Generator & Discriminator"
      ],
      "metadata": {
        "id": "LXggN-Hvw0zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Generator：UNet 結構的簡單實作，包含 Encoder、Decoder 和 skip connection\n",
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Encoder: 兩層卷積，逐步下採樣\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1),  # 第一層卷積，輸入通道1，輸出64，kernel=4, stride=2, padding=1\n",
        "            nn.ReLU()                   # 啟用函數\n",
        "        )\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), # 第二層卷積，輸入64，輸出128\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Decoder: 兩層反卷積（上採樣）\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 第一層反卷積，從128回到64，output size 14x14\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 1, 4, 2, 1),   # 最後一層反卷積，輸入128(=64+64)，輸出1通道（灰階），output 28x28\n",
        "            nn.Tanh()  # 將輸出壓到 [-1, 1]，適合生成對抗網路的output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)           # 輸入x，經第一層encoder，shape: (batch, 64, 14, 14)\n",
        "        e2 = self.enc2(e1)          # 經第二層encoder，shape: (batch, 128, 7, 7)\n",
        "        d1 = self.dec1(e2)          # decoder第一層，up-sample到 (batch, 64, 14, 14)\n",
        "        d1_cat = torch.cat([e1, d1], dim=1)  # 與 encoder1 的特徵圖做 channel 維度串接 (skip connection)，shape: (batch, 128, 14, 14)\n",
        "        out = self.dec2(d1_cat)     # 經最後一層反卷積還原至 (batch, 1, 28, 28)\n",
        "        return out\n",
        "\n",
        "# Discriminator：簡單的卷積分類器\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1),      # 第一層卷積，下採樣，輸出 shape (batch, 64, 4, 4)\n",
        "            nn.LeakyReLU(0.2),              # LeakyReLU 啟用函數\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),    # 第二層卷積，下採樣，輸出 shape (batch, 128, 2, 2)\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),                   # 展平成一維\n",
        "            nn.Linear(128*2*2, 1),          # 全連接層，輸入維度512(=128*2*2)，輸出1（真或假）\n",
        "            nn.Sigmoid()                    # Sigmoid輸出為0~1間，代表\"真實\"的機率\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.main(x)  # 前向傳播，傳入圖片，回傳為真的機率"
      ],
      "metadata": {
        "id": "Gwaa9hR5wr1X"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4. 訓練（僅2個epoch，快速測試）"
      ],
      "metadata": {
        "id": "l7c-9wwMw5EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 建立 UNetGenerator 和 Discriminator，分別丟到 GPU（如果有）或 CPU\n",
        "G, D = UNetGenerator().to(device), Discriminator().to(device)\n",
        "loss_fn = nn.BCELoss()   # 二元交叉熵，判別器用於區分真偽\n",
        "l1_loss = nn.L1Loss()    # L1 損失（像素差異），鼓勵生成貼近真實\n",
        "\n",
        "# 建立 Adam optimizer，分別給 G 與 D\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=2e-4)\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=2e-4)\n",
        "\n",
        "# 訓練 2 個 epoch\n",
        "for epoch in range(2):\n",
        "    for imgs, _ in train_loader:   # 取出每一個 batch（imgs shape: [batch, 1, 28, 28]）\n",
        "        imgs = imgs.to(device)     # 放到指定運算裝置\n",
        "        masked = mask_center(imgs, size=8)  # 把中央 8x8 遮起來，模擬修復任務\n",
        "\n",
        "        # 只拿中央 8x8 區塊作為修復目標（ground truth）\n",
        "        real = imgs[:, :, 10:18, 10:18]\n",
        "        # Generator 修補後的結果，同樣只拿中央 8x8 區塊\n",
        "        fake = G(masked)[:, :, 10:18, 10:18]\n",
        "\n",
        "        # === 訓練 Discriminator ===\n",
        "        real_labels = torch.ones(imgs.size(0), 1, device=device)   # 真圖標記為 1\n",
        "        fake_labels = torch.zeros(imgs.size(0), 1, device=device)  # 假圖標記為 0\n",
        "        out_real = D(real)                 # D 判斷真圖\n",
        "        out_fake = D(fake.detach())        # D 判斷假圖（detach 保證不傳遞梯度到 G）\n",
        "        loss_D = (loss_fn(out_real, real_labels) + loss_fn(out_fake, fake_labels)) / 2  # 判別器損失為真假平均\n",
        "        opt_D.zero_grad(); loss_D.backward(); opt_D.step()  # 反向傳播並更新 D\n",
        "\n",
        "        # === 訓練 Generator ===\n",
        "        out_fake = D(fake)  # 用最新 G 結果再判斷一次\n",
        "        # Generator 損失 = 欺騙 D 的 loss + L1（像素）損失（權重 10 可調整）\n",
        "        loss_G = loss_fn(out_fake, real_labels) + 10 * l1_loss(fake, real)\n",
        "        opt_G.zero_grad(); loss_G.backward(); opt_G.step()  # 反向傳播並更新 G\n",
        "\n",
        "    # 每個 epoch 輸出一次 loss\n",
        "    print(f\"Epoch {epoch+1}/2 | Loss_D: {loss_D.item():.4f} | Loss_G: {loss_G.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gte-JeE2wtlQ",
        "outputId": "4245ee84-e7c3-425b-f5aa-040411369801"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 | Loss_D: 0.6634 | Loss_G: 2.8978\n",
            "Epoch 2/2 | Loss_D: 0.6311 | Loss_G: 2.6153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. 展示修復效果"
      ],
      "metadata": {
        "id": "jvcqiGa_yRaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 從訓練資料中隨機取出一個 batch，並只用第一張圖做測試\n",
        "imgs, _ = next(iter(train_loader))\n",
        "test_img = imgs[0:1].to(device)  # 取出第 0 張圖，shape: [1, 1, 28, 28]\n",
        "\n",
        "# 用和訓練相同的遮罩方式，遮蔽中央 8x8 區塊\n",
        "masked = mask_center(test_img, size=8)\n",
        "\n",
        "with torch.no_grad():  # 測試時不用計算梯度（節省運算資源）\n",
        "    output = G(masked).cpu()  # 將遮罩圖丟到 Generator，產生修復圖，並移到 CPU\n",
        "    repaired = masked.cpu().clone()  # 複製遮罩圖當基底\n",
        "    # 只用 Generator 的 output 取代中央 8x8 區塊，其餘維持原遮罩圖\n",
        "    repaired[:, :, 10:18, 10:18] = output[:, :, 10:18, 10:18]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,3))\n",
        "# 顯示原圖\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(test_img.cpu()[0][0], cmap='gray')\n",
        "plt.title('Original')\n",
        "plt.axis('off')\n",
        "# 顯示遮罩圖（中央 8x8 已遮蔽）\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(masked.cpu()[0][0], cmap='gray')\n",
        "plt.title('Masked')\n",
        "plt.axis('off')\n",
        "# 顯示修復圖（中央區塊已用 Generator 修補）\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(repaired[0][0], cmap='gray')\n",
        "plt.title('Repaired')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "MoZaK1yOw7k1",
        "outputId": "5389977e-336b-407f-ab65-a9b5adcf25ea"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZ597DUS4CS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q5s4-2nn4yfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o--ttbIA5njX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}