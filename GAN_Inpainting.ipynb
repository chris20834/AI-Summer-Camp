{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQzGLCozand+9VitlFH8CW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chris20834/AI-Summer-Camp/blob/main/GAN_Inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. 安裝必要套件"
      ],
      "metadata": {
        "id": "myHUxTqAvP8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_uHdhptvF7G"
      },
      "outputs": [],
      "source": [
        "import torch  # 匯入 PyTorch 主套件，用於 tensor 運算與神經網路\n",
        "from torchvision import datasets, transforms  # 匯入 torchvision 的資料集與資料預處理模組\n",
        "from torch.utils.data import DataLoader  # 匯入 DataLoader，用於批次資料載入\n",
        "import matplotlib.pyplot as plt  # 匯入 matplotlib，用於畫圖顯示"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. 數據集下載與遮罩函數"
      ],
      "metadata": {
        "id": "hvE0uLKywvWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義一個資料轉換：將圖片轉為 Tensor 格式（0~1，且多增加一個 channel 維度）\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# 載入 MNIST 手寫數字訓練資料集\n",
        "# root: 資料存放路徑\n",
        "# train=True: 使用訓練集\n",
        "# download=True: 如果沒有資料就下載\n",
        "# transform=transform: 圖片先做 ToTensor 處理\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# 建立 DataLoader，設定 batch 大小為 64，並在每個 epoch 隨機打亂\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# 定義遮罩函式，將圖片中央的正方形區塊設為 0（黑色遮罩）\n",
        "def mask_center(imgs, size=14):\n",
        "    imgs = imgs.clone()  # 複製一份，不修改原 tensor\n",
        "    c = imgs.size(2) // 2  # 取得圖片中心點座標（以height為例：28//2=14）\n",
        "    l = size // 2  # 遮罩區塊半徑（例如size=14時，l=7）\n",
        "    # 遮罩中央區塊：[中心-l, 中心+l)，同時套用於高度和寬度\n",
        "    imgs[:, :, c-l:c+l, c-l:c+l] = 0\n",
        "    return imgs  # 回傳加上中央遮罩的新圖片張量"
      ],
      "metadata": {
        "id": "xn4MRUWXvKlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. 建立 Generator & Discriminator\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LXggN-Hvw0zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Generator：UNet 結構的簡單實作，包含 Encoder、Decoder 和 skip connection\n",
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Encoder: 兩層卷積，逐步下採樣\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1),  # 第一層卷積，輸入通道1，輸出64，kernel=4, stride=2, padding=1\n",
        "            nn.ReLU()                   # 啟用函數\n",
        "        )\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), # 第二層卷積，輸入64，輸出128\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Decoder: 兩層反卷積（上採樣）\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 第一層反卷積，從128回到64，output size 14x14\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 1, 4, 2, 1),   # 最後一層反卷積，輸入128(=64+64)，輸出1通道（灰階），output 28x28\n",
        "            nn.Tanh()  # 將輸出壓到 [-1, 1]，適合生成對抗網路的output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)           # 輸入x，經第一層encoder，shape: (batch, 64, 14, 14)\n",
        "        e2 = self.enc2(e1)          # 經第二層encoder，shape: (batch, 128, 7, 7)\n",
        "        d1 = self.dec1(e2)          # decoder第一層，up-sample到 (batch, 64, 14, 14)\n",
        "        d1_cat = torch.cat([e1, d1], dim=1)  # 與 encoder1 的特徵圖做 channel 維度串接 (skip connection)，shape: (batch, 128, 14, 14)\n",
        "        out = self.dec2(d1_cat)     # 經最後一層反卷積還原至 (batch, 1, 28, 28)\n",
        "        return out\n",
        "\n",
        "# Discriminator：簡單的卷積分類器\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1),      # 第一層卷積，下採樣，輸出 shape (batch, 64, 4, 4)\n",
        "            nn.LeakyReLU(0.2),              # LeakyReLU 啟用函數\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),    # 第二層卷積，下採樣，輸出 shape (batch, 128, 2, 2)\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),                   # 展平成一維\n",
        "            nn.Linear(128*2*2, 1),          # 全連接層，輸入維度512(=128*2*2)，輸出1（真或假）\n",
        "            nn.Sigmoid()                    # Sigmoid輸出為0~1間，代表\"真實\"的機率\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.main(x)  # 前向傳播，傳入圖片，回傳為真的機率"
      ],
      "metadata": {
        "id": "Gwaa9hR5wr1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4. 訓練（僅2個epoch，快速測試）"
      ],
      "metadata": {
        "id": "l7c-9wwMw5EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 建立模型到 GPU 或 CPU\n",
        "G, D = UNetGenerator().to(device), Discriminator().to(device)\n",
        "loss_fn = nn.BCELoss()   # 判別器損失\n",
        "l1_loss = nn.L1Loss()    # 像素損失\n",
        "\n",
        "# Optimizer\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=2e-4)\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=2e-4)\n",
        "\n",
        "for epoch in range(2):\n",
        "    for imgs, _ in train_loader:   # 取得一批圖片\n",
        "        imgs = imgs.to(device)\n",
        "        masked = mask_center(imgs, size=8)  # 遮罩中心區塊\n",
        "\n",
        "        real = imgs[:, :, 10:18, 10:18]     # 原圖中心\n",
        "        fake = G(masked)[:, :, 10:18, 10:18]# 修復區塊\n",
        "\n",
        "        # 訓練判別器\n",
        "        real_labels = torch.ones(imgs.size(0), 1, device=device)\n",
        "        fake_labels = torch.zeros(imgs.size(0), 1, device=device)\n",
        "        out_real = D(real)\n",
        "        out_fake = D(fake.detach())\n",
        "        loss_D = (loss_fn(out_real, real_labels) + loss_fn(out_fake, fake_labels)) / 2\n",
        "        opt_D.zero_grad(); loss_D.backward(); opt_D.step()\n",
        "\n",
        "        # 訓練生成器\n",
        "        out_fake = D(fake)\n",
        "        loss_G = loss_fn(out_fake, real_labels) + 10 * l1_loss(fake, real)\n",
        "        opt_G.zero_grad(); loss_G.backward(); opt_G.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/2 | Loss_D: {loss_D.item():.4f} | Loss_G: {loss_G.item():.4f}\")"
      ],
      "metadata": {
        "id": "Gte-JeE2wtlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. 展示修復效果"
      ],
      "metadata": {
        "id": "jvcqiGa_yRaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 從訓練資料中隨機取出一個 batch，並只用第一張圖做測試\n",
        "imgs, _ = next(iter(train_loader))\n",
        "test_img = imgs[0:1].to(device)\n",
        "\n",
        "# 遮住中心8x8區塊\n",
        "masked = mask_center(test_img, size=8)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = G(masked).cpu()\n",
        "    repaired = masked.cpu().clone()\n",
        "    repaired[:, :, 10:18, 10:18] = output[:, :, 10:18, 10:18]\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "# 顯示原圖\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(test_img.cpu()[0][0], cmap='gray')\n",
        "plt.title('Original')\n",
        "plt.axis('off')\n",
        "# 顯示遮罩圖（中央 8x8 已遮蔽）\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(masked.cpu()[0][0], cmap='gray')\n",
        "plt.title('Masked')\n",
        "plt.axis('off')\n",
        "# 顯示修復圖（中央區塊已用 Generator 修補）\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(repaired[0][0], cmap='gray')\n",
        "plt.title('Repaired')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MoZaK1yOw7k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6. 修復自己提供的照片"
      ],
      "metadata": {
        "id": "cQ5R4mkNP5v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # 選擇你的手寫數字 PNG 或 JPG 檔案"
      ],
      "metadata": {
        "id": "hZ597DUS4CS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "#import torchvision.transforms as T\n",
        "#import torch\n",
        "\n",
        "# 讀取圖片（檔名請改成你剛上傳的）\n",
        "img = Image.open('9.jpg').convert('L')  # 'L' 代表灰階\n",
        "img = img.resize((28,28))  # 若不是28x28，自動調整\n",
        "transform = transforms.ToTensor()\n",
        "img_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "# 若你的網路在 GPU，需放到同一裝置\n",
        "test_img = img_tensor.to(device)\n",
        "\n",
        "# 遮住中心8x8區塊\n",
        "masked = mask_center(test_img, size=8)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = G(masked).cpu()\n",
        "    repaired = masked.cpu().clone()\n",
        "    repaired[:, :, 10:18, 10:18] = output[:, :, 10:18, 10:18]\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "# 顯示原圖\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(test_img.cpu()[0][0], cmap='gray')\n",
        "plt.title('Original')\n",
        "plt.axis('off')\n",
        "# 顯示遮罩圖（中央 8x8 已遮蔽）\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(masked.cpu()[0][0], cmap='gray')\n",
        "plt.title('Masked')\n",
        "plt.axis('off')\n",
        "# 顯示修復圖（中央區塊已用 Generator 修補）\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(repaired[0][0], cmap='gray')\n",
        "plt.title('Repaired')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q5s4-2nn4yfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36xAJc5mPm63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bu-s0nppjEHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDbUb79HjEUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mj8IeNZfjKUw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}